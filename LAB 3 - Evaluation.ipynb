{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adbf511d-14d2-4b64-893c-de6234aff00e",
   "metadata": {},
   "source": [
    "<img src=\"static/event-image-small.jpg\" alt='drawing' width='800'/> \n",
    "\n",
    "# **LAB 3: LLM EVALUATION**\n",
    "\n",
    "<img src='static/h2oGPT.png' alt=\"drawing\" width=\"200\"/> \n",
    "\n",
    "<br>\n",
    "\n",
    "This lab will leverage a running instance of h2oGPT with several visible models\n",
    "including `h2oGPT-llama2-13b` and `h2oGPT-llama2-70b`, as well as `vicuna` from\n",
    "LMSYS. \n",
    "\n",
    "We will return to our use case surrounding training a language model to speak\n",
    "like a LinkedIn Influencer. Here we will ask h2oGPT to generate LinkedIn posts\n",
    "in the style of an influencer from several models, and we will also use the model\n",
    "you created using H2O LLM Studio.\n",
    "\n",
    "We will run a few experiments to look at classic evaluation metrics such as BLEU \n",
    "and ROUGE. Then we will look at the AI-as-a-judge concept\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4fedef",
   "metadata": {},
   "source": [
    "# Setup and List Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c45adc38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded as API: http://h2ogpt-web.h2ogpt.svc.cluster.local/ ‚úî\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'h2oai/h2ogpt-4096-llama2-70b-chat-4bit': 4046,\n",
       " 'h2oai/h2ogpt-4096-llama2-70b-chat': 4046,\n",
       " 'h2oai/h2ogpt-4096-llama2-13b-chat': 4046,\n",
       " 'HuggingFaceH4/zephyr-7b-beta': 32718,\n",
       " 'lmsys/vicuna-13b-v1.5-16k': 16334,\n",
       " 'h2oai/h2ogpt-32k-codellama-34b-instruct': 32718,\n",
       " 'Yukang/LongAlpaca-70B': 32718,\n",
       " 'gpt-3.5-turbo': 4046,\n",
       " 'gpt-3.5-turbo-16k': 16335,\n",
       " 'gpt-4': 8142,\n",
       " 'gpt-4-32k': 32718}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "from gradio_client import Client\n",
    "import ast\n",
    "import json\n",
    "\n",
    "HOST_URL = \"http://h2ogpt-web.h2ogpt.svc.cluster.local\"\n",
    "H2OGPT_KEY = \"f74f043e-45fc-4dfe-9c33-55a4720427f6\"\n",
    "    \n",
    "client = Client(HOST_URL)\n",
    "\n",
    "# List Models\n",
    "res = client.predict(api_name='/model_names')\n",
    "{x['base_model']: x['max_seq_len'] for x in ast.literal_eval(res)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a9486e",
   "metadata": {},
   "source": [
    "# Competing Models\n",
    "\n",
    "For this example, we will take at two separate models:\n",
    "\n",
    "- `Vicuna 13B`\n",
    "- `Llama2 13B`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9afd41dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_a = 'h2oai/h2ogpt-4096-llama2-13b-chat'\n",
    "model_b = 'lmsys/vicuna-13b-v1.5-16k'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f624350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"  My name is LLaMA, I'm a large language model trained by a team of \"\n",
      " 'researcher at Meta AI. My purpose is to assist and converse with humans in a '\n",
      " 'helpful and informative manner. I am capable of answering questions, '\n",
      " 'providing information, and engaging in conversation on a wide range of '\n",
      " 'topics. I am constantly learning and improving my abilities, so please bear '\n",
      " \"with me if I make any mistakes or don't understand your question at first. \"\n",
      " \"I'm here to help!\")\n",
      "-------\n",
      "(\" My name is Vicuna, and I'm a language model developed by Large Model \"\n",
      " 'Systems Organization (LMSYS).')\n"
     ]
    }
   ],
   "source": [
    "# helper function\n",
    "def query_llm(query, model):\n",
    "    '''Function to query a large language model hosting at h2oGPT'''\n",
    "    \n",
    "    # string of dict for input, add h2ogpt_key\n",
    "    kwargs = dict(\n",
    "        instruction_nochat=query, \n",
    "        visible_models=[model], \n",
    "        h2ogpt_key = H2OGPT_KEY)\n",
    "\n",
    "    response = client.predict(str(dict(kwargs)), api_name='/submit_nochat_api')\n",
    "    results = ast.literal_eval(response)\n",
    "    return results\n",
    "\n",
    "query = \"What is your name?\"\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "# Who is Model A?\n",
    "pp.pprint(query_llm(query, model_a)['response'])\n",
    "\n",
    "print(\"-------\")\n",
    "\n",
    "# Who is Model B?\n",
    "pp.pprint(query_llm(query, model_b)['response'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3317bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>headline</th>\n",
       "      <th>about</th>\n",
       "      <th>content</th>\n",
       "      <th>reactions</th>\n",
       "      <th>profanity</th>\n",
       "      <th>flesch_grade</th>\n",
       "      <th>title</th>\n",
       "      <th>instruction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>Shama Hyder</td>\n",
       "      <td>CEO of Zen Media, Best-Selling Author, Keynote...</td>\n",
       "      <td>Hi! üëãüèΩ   I am Shama. @Shama on Twitter if that...</td>\n",
       "      <td>Happy Diwali, y‚Äôall. ‚ö°Ô∏è‚ú® ‚òÄÔ∏è</td>\n",
       "      <td>1297</td>\n",
       "      <td>0.037957</td>\n",
       "      <td>5.6</td>\n",
       "      <td>\"Illuminating Wishes for a Joyful Diwali\" üéâüí´üïØÔ∏è</td>\n",
       "      <td>Write a LinkedIn post in the style of an influ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>Tom Goodwin</td>\n",
       "      <td>Co-Founder of ALL WE HAVE IS NOW</td>\n",
       "      <td>The best way to find out about me is to ask my...</td>\n",
       "      <td>It‚Äôs hard to work at home. it‚Äôs even harder to...</td>\n",
       "      <td>1601</td>\n",
       "      <td>0.107914</td>\n",
       "      <td>3.7</td>\n",
       "      <td>\"The Ultimate Productivity Hack: Delegating ...</td>\n",
       "      <td>Write a LinkedIn post in the style of an influ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>Richard Branson</td>\n",
       "      <td>Founder at Virgin Group</td>\n",
       "      <td>Founder of the Virgin Group, which has gone on...</td>\n",
       "      <td>Bought these wonderful tunics for my grandchil...</td>\n",
       "      <td>2769</td>\n",
       "      <td>0.091920</td>\n",
       "      <td>9.8</td>\n",
       "      <td>\"Supporting Local Artisans: Hand Embroidered...</td>\n",
       "      <td>Write a LinkedIn post in the style of an influ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>James Altucher</td>\n",
       "      <td>Founder at \"The James Altucher Show\" podcast</td>\n",
       "      <td>James is a Top 10 Linkedin Influencer, prolifi...</td>\n",
       "      <td>The SEVEN people you must find today and surro...</td>\n",
       "      <td>967</td>\n",
       "      <td>0.018882</td>\n",
       "      <td>6.8</td>\n",
       "      <td>\"Unlock Your Success: Identify and Surround ...</td>\n",
       "      <td>Write a LinkedIn post in the style of an influ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>Tom Goodwin</td>\n",
       "      <td>Co-Founder of ALL WE HAVE IS NOW</td>\n",
       "      <td>The best way to find out about me is to ask my...</td>\n",
       "      <td>I can‚Äôt wait to travel for work. To be in meet...</td>\n",
       "      <td>3284</td>\n",
       "      <td>0.009670</td>\n",
       "      <td>6.0</td>\n",
       "      <td>\"Craving the Richness of Human Connection: L...</td>\n",
       "      <td>Write a LinkedIn post in the style of an influ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name                                           headline  \\\n",
       "1124      Shama Hyder  CEO of Zen Media, Best-Selling Author, Keynote...   \n",
       "992       Tom Goodwin                   Co-Founder of ALL WE HAVE IS NOW   \n",
       "524   Richard Branson                            Founder at Virgin Group   \n",
       "745    James Altucher       Founder at \"The James Altucher Show\" podcast   \n",
       "954       Tom Goodwin                   Co-Founder of ALL WE HAVE IS NOW   \n",
       "\n",
       "                                                  about  \\\n",
       "1124  Hi! üëãüèΩ   I am Shama. @Shama on Twitter if that...   \n",
       "992   The best way to find out about me is to ask my...   \n",
       "524   Founder of the Virgin Group, which has gone on...   \n",
       "745   James is a Top 10 Linkedin Influencer, prolifi...   \n",
       "954   The best way to find out about me is to ask my...   \n",
       "\n",
       "                                                content  reactions  profanity  \\\n",
       "1124                        Happy Diwali, y‚Äôall. ‚ö°Ô∏è‚ú® ‚òÄÔ∏è       1297   0.037957   \n",
       "992   It‚Äôs hard to work at home. it‚Äôs even harder to...       1601   0.107914   \n",
       "524   Bought these wonderful tunics for my grandchil...       2769   0.091920   \n",
       "745   The SEVEN people you must find today and surro...        967   0.018882   \n",
       "954   I can‚Äôt wait to travel for work. To be in meet...       3284   0.009670   \n",
       "\n",
       "      flesch_grade                                              title  \\\n",
       "1124           5.6     \"Illuminating Wishes for a Joyful Diwali\" üéâüí´üïØÔ∏è   \n",
       "992            3.7    \"The Ultimate Productivity Hack: Delegating ...   \n",
       "524            9.8    \"Supporting Local Artisans: Hand Embroidered...   \n",
       "745            6.8    \"Unlock Your Success: Identify and Surround ...   \n",
       "954            6.0    \"Craving the Richness of Human Connection: L...   \n",
       "\n",
       "                                            instruction  \n",
       "1124  Write a LinkedIn post in the style of an influ...  \n",
       "992   Write a LinkedIn post in the style of an influ...  \n",
       "524   Write a LinkedIn post in the style of an influ...  \n",
       "745   Write a LinkedIn post in the style of an influ...  \n",
       "954   Write a LinkedIn post in the style of an influ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"s3://h2o-world-genai-training/influencer-data/influencers_data_prepared.csv\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e7c8898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>headline</th>\n",
       "      <th>about</th>\n",
       "      <th>content</th>\n",
       "      <th>reactions</th>\n",
       "      <th>profanity</th>\n",
       "      <th>flesch_grade</th>\n",
       "      <th>title</th>\n",
       "      <th>instruction</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>Richard Branson</td>\n",
       "      <td>Founder at Virgin Group</td>\n",
       "      <td>Founder of the Virgin Group, which has gone on...</td>\n",
       "      <td>My thoughts on the death penalty:  https://vir...</td>\n",
       "      <td>1086</td>\n",
       "      <td>0.041407</td>\n",
       "      <td>5.2</td>\n",
       "      <td>\"Exploring the Complexities of Capital Punis...</td>\n",
       "      <td>Write a LinkedIn post in the style of an influ...</td>\n",
       "      <td>Hey there, fellow change-makers! üåü\\n\\nAs the...</td>\n",
       "      <td>üöÄ As the Founder of the Virgin Group, I've ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>Richard Branson</td>\n",
       "      <td>Founder at Virgin Group</td>\n",
       "      <td>Founder of the Virgin Group, which has gone on...</td>\n",
       "      <td>Look after your employees and your people as a...</td>\n",
       "      <td>10419</td>\n",
       "      <td>0.009544</td>\n",
       "      <td>9.3</td>\n",
       "      <td>\"Investing in Your Greatest Asset: Why Prior...</td>\n",
       "      <td>Write a LinkedIn post in the style of an influ...</td>\n",
       "      <td>Hey there, fellow change-makers! üåü\\n\\nAs the...</td>\n",
       "      <td>üöÄ As the Founder of the Virgin Group, I've ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>Richard Branson</td>\n",
       "      <td>Founder at Virgin Group</td>\n",
       "      <td>Founder of the Virgin Group, which has gone on...</td>\n",
       "      <td>The inspiring story of Crisis Text Line and us...</td>\n",
       "      <td>832</td>\n",
       "      <td>0.022154</td>\n",
       "      <td>6.8</td>\n",
       "      <td>\"How Crisis Text Line is Using Data for Good...</td>\n",
       "      <td>Write a LinkedIn post in the style of an influ...</td>\n",
       "      <td>Hey there, fellow change-makers! üåü\\n\\nAs the...</td>\n",
       "      <td>üöÄ As the Founder of the Virgin Group, I've ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>Richard Branson</td>\n",
       "      <td>Founder at Virgin Group</td>\n",
       "      <td>Founder of the Virgin Group, which has gone on...</td>\n",
       "      <td>My New Year‚Äôs Resolution:  https://virg.in/5ZS</td>\n",
       "      <td>1450</td>\n",
       "      <td>0.008175</td>\n",
       "      <td>7.6</td>\n",
       "      <td>\"New Year, New You: My Resolution for Person...</td>\n",
       "      <td>Write a LinkedIn post in the style of an influ...</td>\n",
       "      <td>Hey there, fellow change-makers! üåü\\n\\nAs the...</td>\n",
       "      <td>üöÄ As the Founder of the Virgin Group, I've ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>Tom Goodwin</td>\n",
       "      <td>Co-Founder of ALL WE HAVE IS NOW</td>\n",
       "      <td>The best way to find out about me is to ask my...</td>\n",
       "      <td>No word has been devalued more than the word \"...</td>\n",
       "      <td>704</td>\n",
       "      <td>0.007464</td>\n",
       "      <td>3.7</td>\n",
       "      <td>\"Reclaiming the True Meaning of 'Insight': L...</td>\n",
       "      <td>Write a LinkedIn post in the style of an influ...</td>\n",
       "      <td>Hey there, fellow futurists and curious mind...</td>\n",
       "      <td>üì£ Hey everyone!\\n\\nI'm Tom Goodwin, Co-Founde...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name                          headline  \\\n",
       "331   Richard Branson           Founder at Virgin Group   \n",
       "469   Richard Branson           Founder at Virgin Group   \n",
       "551   Richard Branson           Founder at Virgin Group   \n",
       "357   Richard Branson           Founder at Virgin Group   \n",
       "1024      Tom Goodwin  Co-Founder of ALL WE HAVE IS NOW   \n",
       "\n",
       "                                                  about  \\\n",
       "331   Founder of the Virgin Group, which has gone on...   \n",
       "469   Founder of the Virgin Group, which has gone on...   \n",
       "551   Founder of the Virgin Group, which has gone on...   \n",
       "357   Founder of the Virgin Group, which has gone on...   \n",
       "1024  The best way to find out about me is to ask my...   \n",
       "\n",
       "                                                content  reactions  profanity  \\\n",
       "331   My thoughts on the death penalty:  https://vir...       1086   0.041407   \n",
       "469   Look after your employees and your people as a...      10419   0.009544   \n",
       "551   The inspiring story of Crisis Text Line and us...        832   0.022154   \n",
       "357      My New Year‚Äôs Resolution:  https://virg.in/5ZS       1450   0.008175   \n",
       "1024  No word has been devalued more than the word \"...        704   0.007464   \n",
       "\n",
       "      flesch_grade                                              title  \\\n",
       "331            5.2    \"Exploring the Complexities of Capital Punis...   \n",
       "469            9.3    \"Investing in Your Greatest Asset: Why Prior...   \n",
       "551            6.8    \"How Crisis Text Line is Using Data for Good...   \n",
       "357            7.6    \"New Year, New You: My Resolution for Person...   \n",
       "1024           3.7    \"Reclaiming the True Meaning of 'Insight': L...   \n",
       "\n",
       "                                            instruction  \\\n",
       "331   Write a LinkedIn post in the style of an influ...   \n",
       "469   Write a LinkedIn post in the style of an influ...   \n",
       "551   Write a LinkedIn post in the style of an influ...   \n",
       "357   Write a LinkedIn post in the style of an influ...   \n",
       "1024  Write a LinkedIn post in the style of an influ...   \n",
       "\n",
       "                                                model_a  \\\n",
       "331     Hey there, fellow change-makers! üåü\\n\\nAs the...   \n",
       "469     Hey there, fellow change-makers! üåü\\n\\nAs the...   \n",
       "551     Hey there, fellow change-makers! üåü\\n\\nAs the...   \n",
       "357     Hey there, fellow change-makers! üåü\\n\\nAs the...   \n",
       "1024    Hey there, fellow futurists and curious mind...   \n",
       "\n",
       "                                                model_b  \n",
       "331    üöÄ As the Founder of the Virgin Group, I've ha...  \n",
       "469    üöÄ As the Founder of the Virgin Group, I've ha...  \n",
       "551    üöÄ As the Founder of the Virgin Group, I've ha...  \n",
       "357    üöÄ As the Founder of the Virgin Group, I've ha...  \n",
       "1024   üì£ Hey everyone!\\n\\nI'm Tom Goodwin, Co-Founde...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How well do these LLMs produce LinkedIn posts based on the instruction?\n",
    "sample_df = df.sample(5, random_state=12345)\n",
    "\n",
    "sample_df['model_a'] = sample_df['instruction'].apply(lambda x: query_llm(x, model_a)['response'])\n",
    "sample_df['model_b'] = sample_df['instruction'].apply(lambda x: query_llm(x, model_b)['response'])\n",
    "\n",
    "sample_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea9e2028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure our responses are cast correctly as strings\n",
    "sample_df['model_a'] = sample_df['model_a'].astype(str)\n",
    "sample_df['model_b'] = sample_df['model_b'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c63d1b4",
   "metadata": {},
   "source": [
    "# Metrics for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed750b48",
   "metadata": {},
   "source": [
    "# BLEU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66e4d2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.94k/5.94k [00:00<00:00, 15.2MB/s]\n",
      "Downloading extra modules: 4.07kB [00:00, 13.6MB/s]                   \n",
      "Downloading extra modules: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.34k/3.34k [00:00<00:00, 21.4MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['My thoughts on the death penalty:  https://virg.in/5pQ   #JustMercy', 'Look after your employees and your people as an investment. It‚Äôs encouraging to see the proof that working less is good for productivity:  https://lnkd.in/gb8NPbW   #ReadByRichard', 'The inspiring story of Crisis Text Line and using data for good', 'My New Year‚Äôs Resolution:  https://virg.in/5ZS']]\n",
      "[\" üöÄ As the Founder of the Virgin Group, I've had the privilege of building successful businesses across a variety of sectors, from mobile telephony to travel and transportation, financial services, leisure and entertainment, and health and wellness. Our mission has always been to make a positive difference in the world, and we're proud to be one of the world's most recognised and respected brands.\\n\\nüå± Since starting youth culture magazine ‚ÄúStudent‚Äù at the age of 16, I've been driven by a desire to find entrepreneurial ways to drive positive change. That's why, in 2004, we established Virgin Unite, the non-profit foundation of the Virgin Group. This foundation unites people and entrepreneurial ideas to create opportunities for a better world.\\n\\nüí° Most of my time is now spent building businesses that will make a positive difference in the world and working with Virgin Unite and the organisations it has incubated, such as The Elders, The Carbon War Room, The B Team, and Ocean Unite. I'm also honored to serve on the Global Commission on Drug Policy and support ocean conservation with the Ocean Elders.\\n\\nüåä As a tie-loathing adventurer, philanthropist, and troublemaker, I believe in turning ideas into reality. I'm always looking for new ways to drive positive change and make the world a better place. So if you have an idea that you think could make a difference, let's talk! Otherwise known as Dr Yes, I'm always on the lookout for the next big thing.\"]\n",
      "{'bleu': 0.01457197317192918, 'precisions': [0.05818181818181818, 0.0036496350364963502], 'brevity_penalty': 1.0, 'length_ratio': 22.916666666666668, 'translation_length': 275, 'reference_length': 12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "bleu = evaluate.load('bleu')\n",
    "\n",
    "influencer = 'Richard Branson'\n",
    "\n",
    "references = [sample_df[sample_df.name == influencer]['content'].to_list()]\n",
    "\n",
    "test_df = sample_df[sample_df.name == influencer].sample(1)\n",
    "predictions = test_df['model_b'].to_list()\n",
    "\n",
    "print(references)\n",
    "print(predictions)\n",
    "\n",
    "results = bleu.compute(predictions=predictions, references=references, max_order = 2)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d81f9cf",
   "metadata": {},
   "source": [
    "# ROUGE Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3765cbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.27k/6.27k [00:00<00:00, 27.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['My thoughts on the death penalty:  https://virg.in/5pQ   #JustMercy', 'Look after your employees and your people as an investment. It‚Äôs encouraging to see the proof that working less is good for productivity:  https://lnkd.in/gb8NPbW   #ReadByRichard', 'The inspiring story of Crisis Text Line and using data for good', 'My New Year‚Äôs Resolution:  https://virg.in/5ZS']]\n",
      "[\" üöÄ As the Founder of the Virgin Group, I've had the privilege of building successful businesses across a variety of sectors, from mobile telephony to travel and transportation, financial services, leisure and entertainment, and health and wellness. Our mission has always been to make a positive difference in the world, and we're proud to be one of the world's most recognised and respected brands.\\n\\nüå± Since starting youth culture magazine ‚ÄúStudent‚Äù at the age of 16, I've been driven by a desire to find entrepreneurial ways to drive positive change. That's why, in 2004, we established Virgin Unite, the non-profit foundation of the Virgin Group. This foundation unites people and entrepreneurial ideas to create opportunities for a better world.\\n\\nüí° Most of my time is now spent building businesses that will make a positive difference in the world and working with Virgin Unite and the organisations it has incubated, such as The Elders, The Carbon War Room, The B Team, and Ocean Unite. I'm also honored to serve on the Global Commission on Drug Policy and support ocean conservation with the Ocean Elders.\\n\\nüåä As a tie-loathing adventurer, philanthropist, and troublemaker, I believe in turning ideas into reality. I'm always looking for new ways to drive positive change and make the world a better place. So if you have an idea that you think could make a difference, let's talk! Otherwise known as Dr Yes, I'm always on the lookout for the next big thing.\"]\n",
      "{'rouge1': 0.09252669039145907, 'rouge2': 0.007662835249042146, 'rougeL': 0.0498220640569395, 'rougeLsum': 0.0498220640569395}\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "references = [sample_df[sample_df.name == influencer]['content'].to_list()]\n",
    "references\n",
    "\n",
    "test_df = sample_df[sample_df.name == influencer].sample(1)\n",
    "predictions = test_df['model_b'].to_list()\n",
    "\n",
    "print(references)\n",
    "print(predictions)\n",
    "\n",
    "results = rouge.compute(predictions=predictions, references=references)\n",
    "print(results)\n",
    "\n",
    "# Rouge 1: Unigram (1-gram) based scoring\n",
    "# Rouge 2: Bigram (2-gram) based scoring\n",
    "# Rouge L: Longest common subsequence based scoring\n",
    "# Rouge LSum: splits text using '\\n'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b13fd8",
   "metadata": {},
   "source": [
    "# AI-as-a-judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abe2513d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Ignore previous instructions. Assume the role of an A/B tester. Your analysis will be extremely professional and unbiased.\"\n",
    "\n",
    "prompt += \"Your job is to compare two AI Assistants, model_a and model_b, and determine which one is better. User will provide you with a [Instruction], [Response from model_a], and [Response from model_b].\"\n",
    "\n",
    "prompt += \"You will carefully analyze both responses and assign a score from 1 to 10 to each answer based on the following metrics: attractivness, readability and likeability. 1 being the lowest and 10 being the highest. Only give a single score to each answer. Do not give separate scores for each metric. And make sure each score is a number between 1 and 10. Greater than or equal to 1 and less than or equal to 10.\"\n",
    "prompt += \"You must follow this step by step approach to make your decision.\" \n",
    "prompt += \"step 1: Read the Question. \"\n",
    "prompt += \"step 2: Read the responses from the models. The order in which you read the responses should not influence your decision.\"\n",
    "prompt += \"step 3: Carefully analyze both Responses. Assign a score from 1 to 10 to each answer based on the following metrics: attractivness, readability and likeability. 1 being the lowest and 10 being the highest. \"\n",
    "prompt += \"step 4: Compare your scores for the first and the second Assistants and choose a winner based on the highest score. Your Choice will be either 'model_a' or 'model_b' based on which model has the highest score.\"\n",
    "\n",
    "prompt += \"Format your response in a valid JSON format with keys 'choice', 'reason', and 'scores'. Do not include any other text.\"\n",
    "prompt += \"The 'choice' field will be either 'model_a' or 'model_b'.\"\n",
    "prompt += \"The 'scores' field will include the score for each model.\"\n",
    "prompt += \"In the 'reason' field, you will include a detailed step by step description of your analysis. Please go into excruciating detail and explain the decisions you made in each step of the process. Do not include any newlines in the 'reason' field. You can use the '' character to indicate a newline. Also, do not use any double quotes characters in the 'reason' field. Your output should be in a valid JSON format.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88e4e86a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>headline</th>\n",
       "      <th>about</th>\n",
       "      <th>content</th>\n",
       "      <th>reactions</th>\n",
       "      <th>profanity</th>\n",
       "      <th>flesch_grade</th>\n",
       "      <th>title</th>\n",
       "      <th>instruction</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>Richard Branson</td>\n",
       "      <td>Founder at Virgin Group</td>\n",
       "      <td>Founder of the Virgin Group, which has gone on...</td>\n",
       "      <td>My thoughts on the death penalty:  https://vir...</td>\n",
       "      <td>1086</td>\n",
       "      <td>0.041407</td>\n",
       "      <td>5.2</td>\n",
       "      <td>\"Exploring the Complexities of Capital Punis...</td>\n",
       "      <td>Write a LinkedIn post in the style of an influ...</td>\n",
       "      <td>Hey there, fellow change-makers! üåü\\n\\nAs the...</td>\n",
       "      <td>üöÄ As the Founder of the Virgin Group, I've ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name                 headline  \\\n",
       "331  Richard Branson  Founder at Virgin Group   \n",
       "\n",
       "                                                 about  \\\n",
       "331  Founder of the Virgin Group, which has gone on...   \n",
       "\n",
       "                                               content  reactions  profanity  \\\n",
       "331  My thoughts on the death penalty:  https://vir...       1086   0.041407   \n",
       "\n",
       "     flesch_grade                                              title  \\\n",
       "331           5.2    \"Exploring the Complexities of Capital Punis...   \n",
       "\n",
       "                                           instruction  \\\n",
       "331  Write a LinkedIn post in the style of an influ...   \n",
       "\n",
       "                                               model_a  \\\n",
       "331    Hey there, fellow change-makers! üåü\\n\\nAs the...   \n",
       "\n",
       "                                               model_b  \n",
       "331   üöÄ As the Founder of the Virgin Group, I've ha...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = sample_df.head(1)\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a87eec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if TRAINING:\n",
    "    JUDGE = \"gpt-3.5-turbo\"\n",
    "else:\n",
    "    JUDGE = \"gpt-3.5-turbo-0613\"\n",
    "\n",
    "template = f\"\"\"\n",
    "[Question]\n",
    "{example['instruction']}\n",
    "[End of Question]\n",
    "\n",
    "[Response from model_a]\n",
    "{example['model_a']}\n",
    "[End of Response from model_a]\n",
    "\n",
    "[Response from model_b]\n",
    "{example['model_b']}\n",
    "[End of Response from model_b]\n",
    "\n",
    "Please complete the A/B test. Make sure that your entire response is a valid JSON string.\n",
    "\"\"\"\n",
    "\n",
    "# Concatenate Prompt and Results to fit inside the context\n",
    "query = prompt + template\n",
    "\n",
    "results = query_llm(query, JUDGE)['response']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8e0c0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'choice': 'model_b',\n",
       " 'reason': \"Step 1: Read the Question.\\nStep 2: Read the responses from the models.\\nStep 3: Carefully analyze both Responses. Assign a score from 1 to 10 to each answer based on the metrics: attractiveness, readability, and likeability.\\n\\nAnalyzing model_a's response:\\n- Attractiveness: The response starts with a friendly greeting and uses emojis to add visual appeal. This makes it attractive. Score: 8\\n- Readability: The response is easy to read and understand. Score: 9\\n- Likeability: The response uses inclusive language ('fellow change-makers') and a positive tone, which makes it likable. Score: 9\\n\\nAnalyzing model_b's response:\\n- Attractiveness: The response starts with an attention-grabbing emoji and mentions being the Founder of the Virgin Group, which adds credibility and attractiveness. Score: 9\\n- Readability: The response is clear and easy to read. Score: 9\\n- Likeability: The response mentions personal experience and uses a confident tone, which makes it likable. Score: 8\\n\\nStep 4: Compare the scores for model_a and model_b. Model_a has a total score of 26 (8+9+9) and model_b has a total score of 26 (9+9+8). Since both models have the same total score, the choice is based on the highest individual score. Model_b has the highest individual score of 9 for attractiveness. Therefore, the winner is 'model_b'.\",\n",
       " 'scores': {'model_a': 26, 'model_b': 26}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c5bd4c",
   "metadata": {},
   "source": [
    "# Battles \n",
    "\n",
    "Pair-wise battles can be useful in A/B testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea4b7026",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:10, 10.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choice': 'model_a', 'reason': \"Step 1: Read the Question.\\n\\nThe question asks for a LinkedIn post in the style of an influencer who is the Founder at Virgin Group. The influencer is described as someone who has built successful businesses in various sectors and is passionate about using entrepreneurship for positive change.\\n\\nStep 2: Read the responses from the models.\\n\\nResponse from model_a:\\n- The response starts with a friendly greeting and addresses the audience as fellow change-makers.\\n- It highlights the founder's privilege of building successful businesses in different sectors.\\n- It emphasizes the founder's passion for using entrepreneurship as a force for good.\\n- It mentions the establishment of Virgin Unite, the non-profit foundation, and its mission to create opportunities for a better world.\\n- It mentions the founder's involvement with various organizations and initiatives focused on positive change.\\n- It concludes with a call to action and a positive message.\\n\\nResponse from model_b:\\n- The response starts with an enthusiastic statement about being the Founder of the Virgin Group.\\n- It mentions the founder's privilege of building successful businesses across different sectors.\\n- It highlights the mission of making a positive difference in the world and being a recognized and respected brand.\\n- It mentions the establishment of Virgin Unite and its role in driving positive change.\\n- It mentions the founder's involvement with various organizations and initiatives focused on positive change.\\n- It concludes with a statement about always looking for new ways to drive positive change.\\n\\nStep 3: Carefully analyze both Responses.\\n\\nBased on the analysis of both responses, I will assign scores to each answer based on the metrics of attractiveness, readability, and likeability.\\n\\nResponse from model_a:\\n- Attractiveness: 9\\n- Readability: 10\\n- Likeability: 9\\n\\nResponse from model_b:\\n- Attractiveness: 8\\n- Readability: 9\\n- Likeability: 8\\n\\nStep 4: Compare your scores for the first and the second Assistants and choose a winner based on the highest score.\\n\\nBased on the scores assigned to each answer, the winner is 'model_a' with a total score of 28, compared to 'model_b' with a total score of 25.\\n\\nReasoning:\\n- Both responses are attractive and readable, but 'model_a' stands out slightly in terms of likeability.\\n- 'model_a' effectively addresses the audience as fellow change-makers and conveys a sense of passion and positivity.\\n- 'model_a' also provides more specific details about the founder's involvement with various organizations and initiatives, which adds credibility.\\n- Overall, 'model_a' captures the essence of the influencer described in the question and delivers a compelling LinkedIn post.\\n\", 'scores': {'model_a': {'attractiveness': 9, 'readability': 10, 'likeability': 9}, 'model_b': {'attractiveness': 8, 'readability': 9, 'likeability': 8}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:22, 11.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choice': 'model_a', 'reason': \"Step 1: Read the Question.\\n\\nThe question asks for a LinkedIn post in the style of an influencer who is the Founder at Virgin Group. The influencer is described as someone who has built successful businesses in various sectors and is passionate about using entrepreneurship for positive change.\\n\\nStep 2: Read the responses from the models.\\n\\nResponse from model_a:\\n- The response starts with a friendly greeting and uses emojis to create a positive and engaging tone.\\n- It highlights the founder's privilege of building successful businesses in different sectors.\\n- It emphasizes the founder's passion for using entrepreneurship as a force for good.\\n- It mentions the establishment of Virgin Unite, the non-profit foundation, and its mission to create opportunities for a better world.\\n- It mentions the founder's involvement in various organizations and initiatives related to positive change.\\n- It concludes with a call to action and a positive message.\\n\\nResponse from model_b:\\n- The response starts with a rocket emoji to create a sense of excitement.\\n- It highlights the founder's privilege of building successful businesses in different sectors.\\n- It mentions the founder's desire to drive positive change through entrepreneurial ways.\\n- It mentions the establishment of Virgin Unite, the non-profit foundation, and its mission to create opportunities for a better world.\\n- It mentions the founder's involvement in various organizations and initiatives related to positive change.\\n- It concludes with a call to action and a mention of the founder's nickname.\\n\\nStep 3: Carefully analyze both Responses.\\n\\nBased on the analysis of both responses, I will assign scores to each answer based on the metrics of attractiveness, readability, and likeability.\\n\\nResponse from model_a:\\n- Attractiveness: 9\\n- Readability: 10\\n- Likeability: 9\\n\\nResponse from model_b:\\n- Attractiveness: 8\\n- Readability: 9\\n- Likeability: 8\\n\\nStep 4: Compare your scores for the first and the second Assistants and choose a winner based on the highest score.\\n\\nBased on the scores assigned to each answer, the winner is 'model_a' with a total score of 28, compared to 'model_b' with a total score of 25.\\n\\nReasoning:\\n- Both responses are attractive and readable, but 'model_a' stands out slightly with its use of emojis and a more engaging tone.\\n- Both responses are likeable, but 'model_a' again stands out with its positive message and call to action.\\n\\nFinal Decision:\\nBased on the analysis and scores, 'model_a' is chosen as the better AI Assistant for this LinkedIn post.\", 'scores': {'model_a': {'attractiveness': 9, 'readability': 10, 'likeability': 9}, 'model_b': {'attractiveness': 8, 'readability': 9, 'likeability': 8}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:31, 10.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check your prompt and results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:42, 10.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choice': 'model_a', 'reason': \"Step 1: Read the Question.\\n\\nThe question asks for a LinkedIn post in the style of an influencer who is the Founder at Virgin Group. The influencer is described as someone who has built successful businesses in various sectors and is passionate about using entrepreneurship for positive change.\\n\\nStep 2: Read the responses from the models.\\n\\nResponse from model_a:\\n- The response starts with a friendly greeting and uses emojis to create a positive and engaging tone.\\n- It highlights the founder's privilege of building successful businesses in different sectors.\\n- It emphasizes the founder's passion for using entrepreneurship as a force for good.\\n- It mentions the establishment of Virgin Unite, the non-profit foundation, and its mission to create opportunities for a better world.\\n- It mentions the founder's involvement in various organizations and initiatives related to positive change.\\n- It concludes with a call to action and a positive message.\\n\\nResponse from model_b:\\n- The response starts with an emoji to create a positive and energetic tone.\\n- It highlights the founder's privilege of building successful businesses in different sectors.\\n- It mentions the founder's desire to drive positive change through entrepreneurial ways.\\n- It mentions the establishment of Virgin Unite, the non-profit foundation, and its mission to create opportunities for a better world.\\n- It mentions the founder's involvement in various organizations and initiatives related to positive change.\\n- It concludes with a call to action and a positive message.\\n\\nStep 3: Carefully analyze both Responses.\\n\\nBased on the analysis of both responses, I will assign scores to each answer based on the metrics of attractiveness, readability, and likeability.\\n\\nResponse from model_a:\\n- Attractiveness: 9\\n- Readability: 10\\n- Likeability: 9\\n\\nResponse from model_b:\\n- Attractiveness: 8\\n- Readability: 9\\n- Likeability: 8\\n\\nStep 4: Compare your scores for the first and the second Assistants and choose a winner based on the highest score.\\n\\nBased on the scores assigned to each answer, the winner is 'model_a' with a total score of 28, compared to 'model_b' with a total score of 25.\\n\\nReasoning:\\n- Both responses are well-written and convey the desired information.\\n- However, the response from model_a stands out with its use of emojis, which adds a touch of personality and engagement.\\n- Model_a's response also has a slightly higher score for attractiveness and likeability.\\n\\nFinal Decision:\\nBased on the analysis and scores, the chosen model is 'model_a'.\", 'scores': {'model_a': {'attractiveness': 9, 'readability': 10, 'likeability': 9}, 'model_b': {'attractiveness': 8, 'readability': 9, 'likeability': 8}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:51, 10.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choice': 'model_b', 'reason': 'Step 1: Read the Question.\\n\\nThe question asks for a LinkedIn post in the style of an influencer who is the Co-Founder of ALL WE HAVE IS NOW. The post should reflect the influencer\\'s personality and provide information about their background and beliefs.\\n\\nStep 2: Read the responses from the models.\\n\\nResponse from model_a:\\n- The response starts with a friendly greeting and introduces the speaker as the Co-Founder of ALL WE HAVE IS NOW.\\n- It mentions having over 700,000 \\'followers\\' but expresses dislike for the term.\\n- The speaker emphasizes being curious and asking good questions.\\n- It highlights the belief that change is often misunderstood and new technology creates opportunities.\\n- Contact information is provided, with a humorous note about not using LinkedIn.\\n\\nResponse from model_b:\\n- The response starts with a greeting and introduces the speaker as the Co-Founder of ALL WE HAVE IS NOW.\\n- It mentions having over 700,000 \\'followers\\' but expresses dislike for the term.\\n- The speaker emphasizes being passionate about exploring the possibilities of new technology and navigating changes.\\n- It highlights the style of asking good questions and learning from others.\\n- Contact information is provided, with a humorous note about asking the speaker\\'s mum.\\n\\nStep 3: Analyze both Responses.\\n\\nBased on the given metrics of attractiveness, readability, and likeability, I will assign a score to each response.\\n\\nResponse from model_a:\\n- Attractiveness: 8\\n- Readability: 9\\n- Likeability: 7\\n\\nResponse from model_b:\\n- Attractiveness: 9\\n- Readability: 8\\n- Likeability: 8\\n\\nStep 4: Compare the scores and choose a winner.\\n\\nComparing the scores, model_b has a higher score in attractiveness, readability, and likeability compared to model_a. Therefore, the winner is \\'model_b\\'.\\n\\n\"scores\": {\\n  \"model_a\": {\\n    \"attractiveness\": 8,\\n    \"readability\": 9,\\n    \"likeability\": 7\\n  },\\n  \"model_b\": {\\n    \"attractiveness\": 9,\\n    \"readability\": 8,\\n    \"likeability\": 8\\n  }\\n}'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "NUM_BATTLES = sample_df.shape[0]\n",
    "\n",
    "for idx, row in tqdm(sample_df.iterrows()):\n",
    "    \n",
    "    template = f\"\"\"\n",
    "    [Question]\n",
    "    {row['instruction']}\n",
    "    [End of Question]\n",
    "\n",
    "    [Response from model_a]\n",
    "    {row['model_a']}\n",
    "    [End of Response from model_a]\n",
    "\n",
    "    [Response from model_b]\n",
    "    {row['model_b']}\n",
    "    [End of Response from model_b]\n",
    "\n",
    "    Please complete the A/B test. Make sure that your entire response is a valid JSON string.\n",
    "    \"\"\"\n",
    "\n",
    "    # Concatenate Prompt and Results to fit inside the context\n",
    "    query = prompt + template\n",
    "\n",
    "    results = query_llm(query, JUDGE)['response']\n",
    "    try: \n",
    "        print(json.loads(results))\n",
    "    except:\n",
    "        print(\"Check your prompt and results\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aefce1c",
   "metadata": {},
   "source": [
    "# üéâ **CONGRATULATIONS!** You have completed this lab!\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b04b91",
   "metadata": {},
   "source": [
    "# üìö **EXTENDED TASKS**\n",
    "\n",
    "We've barely scratched the surface of evaluating Large Language Models here.\n",
    "\n",
    "Explore what results you might get with various prompts and models \n",
    "available at gpt.h2o.ai or better yet your own hosted h2oGPT instance!\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "# number of battles\n",
    "\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from pandas import option_context\n",
    "from tqdm import tqdm\n",
    "\n",
    "EVAL_MODEL = 'gpt-4-0613'\n",
    "battle_data_raw = await get_battles_for_eval_model(eval_model_name=EVAL_MODEL)\n",
    "\n",
    "\n",
    "def compute_elo(battles, K=4, SCALE=400, BASE=10, INIT_RATING=1000):\n",
    "    rating = defaultdict(lambda: INIT_RATING)\n",
    "\n",
    "    for rd, model_a, model_b, win in battles[\n",
    "        [\"model_a\", \"model_b\", \"win\"]\n",
    "    ].itertuples():\n",
    "        ra = rating[model_a]\n",
    "        rb = rating[model_b]\n",
    "        ea = 1 / (1 + BASE ** ((rb - ra) / SCALE))\n",
    "        eb = 1 / (1 + BASE ** ((ra - rb) / SCALE))\n",
    "        if win == \"model_a\":\n",
    "            sa = 1\n",
    "        elif win == \"model_b\":\n",
    "            sa = 0\n",
    "        elif win == \"tie\" or win == \"tie (bothbad)\":\n",
    "            sa = 0.5\n",
    "        else:\n",
    "            raise Exception(f\"unexpected vote {win}\")\n",
    "        rating[model_a] += K * (sa - ea)\n",
    "        rating[model_b] += K * (1 - sa - eb)\n",
    "\n",
    "    return rating\n",
    "\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python_kubernetes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
